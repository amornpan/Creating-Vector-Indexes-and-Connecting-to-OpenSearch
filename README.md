# ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Hybrid Search ‡∏î‡πâ‡∏ß‡∏¢ OpenSearch ‡πÅ‡∏•‡∏∞ LlamaIndex

## üöÄ ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ô Google Colab

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/amornpan/Creating-Vector-Indexes-and-Connecting-to-OpenSearch/blob/master/opensearch_tutorial.ipynb)

**‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏¥‡∏î Notebook ‡πÉ‡∏ô Google Colab:**

1. ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏õ‡∏∏‡πà‡∏° "Open In Colab" ‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô
2. ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏õ‡∏ó‡∏µ‡πà [opensearch_tutorial.ipynb](https://github.com/amornpan/Creating-Vector-Indexes-and-Connecting-to-OpenSearch/blob/master/opensearch_tutorial.ipynb) ‡πÉ‡∏ô GitHub ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏•‡∏¥‡∏Å‡∏õ‡∏∏‡πà‡∏° "Open in Colab"

## ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡∏ö‡∏ó‡πÄ‡∏£‡∏µ‡∏¢‡∏ô

‡πÉ‡∏ô‡∏ö‡∏ó‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö Hybrid Search ‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏°‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏ö‡∏ö semantic search ‡πÅ‡∏•‡∏∞ keyword search ‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ:
- **OpenSearch** ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö vector database ‡πÅ‡∏•‡∏∞ keyword search
- **LlamaIndex** ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÅ‡∏•‡∏∞ indexing
- **BGE-M3** embedding model ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô vector

---

## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Dependencies

```python
# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á LlamaIndex ‡πÅ‡∏•‡∏∞ dependencies
!pip install llama-index -q
!pip install llama-index-embeddings-huggingface -q
!pip install llama-index-vector-stores-opensearch -q
!pip install requests -q
!pip install nest_asyncio -q
```

**‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:**
- `llama-index`: Framework ‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á RAG applications
- `llama-index-embeddings-huggingface`: ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ embedding models ‡∏à‡∏≤‡∏Å Hugging Face
- `llama-index-vector-stores-opensearch`: connector ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö OpenSearch
- `requests`: ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å HTTP APIs
- `nest_asyncio`: ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ event loop ‡πÉ‡∏ô Jupyter Notebook

---

## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 2: Import Modules ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô

```python
import os
import torch
import urllib.request
import pickle
import requests
import nest_asyncio
import json
from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, StorageContext
from llama_index.core.node_parser import MarkdownNodeParser
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.vector_stores.opensearch import OpensearchVectorStore, OpensearchVectorClient
from llama_index.core.vector_stores.types import VectorStoreQueryMode

# Apply nest_asyncio to avoid runtime errors
nest_asyncio.apply()
```

**‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:**
- Import modules ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
- `nest_asyncio.apply()` ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ async ‡πÉ‡∏ô Jupyter environment

---

## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 3: ‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏≠‡∏ô‡∏ü‡∏¥‡∏Å

```python
# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö OpenSearch
OPENSEARCH_ENDPOINT = "http://34.41.37.53:9200"
OPENSEARCH_INDEX = "aekanun_doc_index"  # ‚ö†Ô∏è ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì
TEXT_FIELD = "content"
EMBEDDING_FIELD = "embedding"

# Check if CUDA is available for GPU acceleration
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"‡πÉ‡∏ä‡πâ‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå: {device}")
```

**‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:**
- ‡∏Å‡∏≥‡∏´‡∏ô‡∏î endpoint ‡∏Ç‡∏≠‡∏á OpenSearch cluster
- ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡∏∑‡πà‡∏≠ index (‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏ô)
- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ GPU ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà

---

## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 4: ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Hybrid Search Pipeline

```python
def create_hybrid_search_pipeline():
    pipeline_url = f"{OPENSEARCH_ENDPOINT}/_search/pipeline/hybrid-search-pipeline"
    headers = {'Content-Type': 'application/json'}

    pipeline_config = {
        "description": "Pipeline for hybrid search",
        "phase_results_processors": [
            {
                "normalization-processor": {
                    "normalization": {
                        "technique": "min_max"
                    },
                    "combination": {
                        "technique": "harmonic_mean",
                        "parameters": {
                            "weights": [0.3, 0.7]  # keyword: 0.3, semantic: 0.7
                        }
                    }
                }
            }
        ]
    }

    try:
        response = requests.put(pipeline_url, headers=headers, data=json.dumps(pipeline_config))
        if response.status_code in [200, 201]:
            print(f"‡∏™‡∏£‡πâ‡∏≤‡∏á hybrid search pipeline ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {response.json()}")
        else:
            print(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á pipeline ‡πÑ‡∏î‡πâ: {response.text}")
    except Exception as e:
        print(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á pipeline: {e}")
```

**‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:**
- ‡∏™‡∏£‡πâ‡∏≤‡∏á search pipeline ‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏° keyword search ‡πÅ‡∏•‡∏∞ semantic search
- ‡πÉ‡∏ä‡πâ min-max normalization ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤ scores ‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
- ‡πÉ‡∏ä‡πâ harmonic mean ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏° scores ‡πÇ‡∏î‡∏¢‡πÉ‡∏´‡πâ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å keyword 30% ‡πÅ‡∏•‡∏∞ semantic 70%

---

## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 5: ‡∏Å‡∏≤‡∏£‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£

```python
def download_corpus():
    os.makedirs('./corpus_input', exist_ok=True)
    urls = [
        ("https://storage.googleapis.com/llm-course/md/1.md", "./corpus_input/1.md"),
        ("https://storage.googleapis.com/llm-course/md/2.md", "./corpus_input/2.md"),
        ("https://storage.googleapis.com/llm-course/md/44.md", "./corpus_input/44.md"),
        ("https://storage.googleapis.com/llm-course/md/5555.md", "./corpus_input/5555.md")
    ]
    for url, path in urls:
        if not os.path.exists(path):
            print(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î {url} ‡πÑ‡∏õ‡∏¢‡∏±‡∏á {path}")
            try:
                urllib.request.urlretrieve(url, path)
            except Exception as e:
                print(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î {url} ‡πÑ‡∏î‡πâ: {e}")

# ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î corpus
print("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå...")
download_corpus()
```

**‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:**
- ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£
- ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Markdown ‡∏à‡∏≤‡∏Å Google Storage
- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏Å‡πà‡∏≠‡∏ô‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î

---

## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 6: ‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡πÅ‡∏¢‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£

```python
# ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ Markdown ‡∏à‡∏≤‡∏Å‡πÑ‡∏î‡πÄ‡∏£‡∏Å‡∏ó‡∏≠‡∏£‡∏µ
reader = SimpleDirectoryReader(
    input_dir="./corpus_input",
    recursive=True,
    required_exts=[".md", ".markdown"]
)
documents = reader.load_data()
print(f"‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ {len(documents)} ‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")

# ‡∏™‡∏£‡πâ‡∏≤‡∏á parser ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Markdown
md_parser = MarkdownNodeParser()
nodes = md_parser.get_nodes_from_documents(documents)
print(f"‡∏™‡∏£‡πâ‡∏≤‡∏á {len(nodes)} nodes ‡∏î‡πâ‡∏ß‡∏¢ MarkdownNodeParser ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
```

**‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:**
- `SimpleDirectoryReader`: ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå
- `MarkdownNodeParser`: ‡πÅ‡∏¢‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ Markdown ‡πÄ‡∏õ‡πá‡∏ô chunks (nodes) ‡∏ï‡∏≤‡∏° structure
- ‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å‡πÄ‡∏õ‡πá‡∏ô nodes ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏î‡πâ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢

---

## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 7: ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Embedding Model

```python
# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ embedding model
embed_model = HuggingFaceEmbedding(model_name="BAAI/bge-m3", device=device)
print(f"‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏• embedding BAAI/bge-m3 ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡∏≠‡∏á embedding
embeddings = embed_model.get_text_embedding("test")
dim = len(embeddings)
print(f"‡∏Ç‡∏ô‡∏≤‡∏î embedding: {dim}")
```

**‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:**
- **BGE-M3**: Multi-lingual embedding model ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
- ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î vector (1024 dimensions)
- ‡∏Å‡∏≤‡∏£‡∏ó‡∏£‡∏≤‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î vector ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ OpenSearch

---

## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 8: ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á OpenSearch Vector Store

```python
# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ OpensearchVectorClient
client = OpensearchVectorClient(
    endpoint=OPENSEARCH_ENDPOINT,
    index=OPENSEARCH_INDEX,
    dim=dim,
    embedding_field=EMBEDDING_FIELD,
    text_field=TEXT_FIELD,
    search_pipeline="hybrid-search-pipeline",
)
print(f"‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ OpensearchVectorClient ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö index '{OPENSEARCH_INDEX}'")

# ‡∏™‡∏£‡πâ‡∏≤‡∏á vector store
vector_store = OpensearchVectorStore(client)

# ‡∏™‡∏£‡πâ‡∏≤‡∏á storage context
storage_context = StorageContext.from_defaults(vector_store=vector_store)
```

**‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:**
- ‡∏™‡∏£‡πâ‡∏≤‡∏á client ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö OpenSearch
- ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ hybrid search pipeline ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ß‡πâ
- `StorageContext`: ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏Å‡πá‡∏ö vectors ‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô

---

## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 9: ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Index ‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å

```python
# ‡∏™‡∏£‡πâ‡∏≤‡∏á index
index = VectorStoreIndex(
    nodes=nodes,
    storage_context=storage_context,
    embed_model=embed_model
)
print(f"‡∏™‡∏£‡πâ‡∏≤‡∏á index ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")

# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å index ‡∏î‡πâ‡∏ß‡∏¢ pickle
index_filename = f"{OPENSEARCH_INDEX}.pkl"
with open(index_filename, 'wb') as f:
    pickle.dump(index, f)
print(f"‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å index ‡∏•‡∏á‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå {index_filename} ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")

print("‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î!")

# ===== üîç ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ =====
from llama_index.core import Settings

# ‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ LLM ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏±‡∏ç‡∏´‡∏≤ OpenAI API key
Settings.llm = None

# Quick test of the search system
print("\nüîç Testing the search system...")

# Create retriever instead of query_engine
retriever = index.as_retriever(
    vector_store_query_mode=VectorStoreQueryMode.HYBRID,
    similarity_top_k=3
)

# Test queries
test_queries = [
    "What is machine learning?",
    "How does artificial intelligence work?", 
    "Explain neural networks",
    "‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Ç‡∏≠‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á"  # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
]

for i, query in enumerate(test_queries, 1):
    print(f"\nüîç Test Query {i}: {query}")
    try:
        nodes = retriever.retrieve(query)
        print(f"‚úÖ Found {len(nodes)} relevant documents:")
        for j, node in enumerate(nodes, 1):
            print(f"  {j}. Score: {node.score:.3f}")
            print(f"     Content: {node.text[:150]}...")
    except Exception as e:
        print(f"‚ùå Error: {e}")

print("\nüéØ Search system is working! Documents are being retrieved successfully.")

# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏ö‡∏ö keyword vs semantic
print("\nüî¨ Testing different search modes...")

# Semantic search only
print("\nüß† Semantic Search:")
semantic_retriever = index.as_retriever(
    vector_store_query_mode=VectorStoreQueryMode.DEFAULT,
    similarity_top_k=2
)

# Keyword search (text search)
print("\nüîç Hybrid Search vs Semantic Search:")
# Note: OpenSearch hybrid search ‡∏à‡∏∞‡∏£‡∏ß‡∏° keyword + semantic ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß

test_query = "machine learning algorithms"
semantic_results = semantic_retriever.retrieve(test_query)
hybrid_results = retriever.retrieve(test_query)

print(f"Query: {test_query}")
print(f"Semantic only: {len(semantic_results)} results")
print(f"Hybrid search: {len(hybrid_results)} results")

print("\n‚ú® Hybrid search test completed!")
```

**‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:**
- ‡∏™‡∏£‡πâ‡∏≤‡∏á `VectorStoreIndex` ‡πÇ‡∏î‡∏¢‡∏™‡πà‡∏á nodes, storage context ‡πÅ‡∏•‡∏∞ embedding model
- LlamaIndex ‡∏à‡∏∞‡πÅ‡∏õ‡∏•‡∏á nodes ‡πÄ‡∏õ‡πá‡∏ô embeddings ‡πÅ‡∏•‡∏∞‡πÄ‡∏Å‡πá‡∏ö‡πÉ‡∏ô OpenSearch
- ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å index object ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÉ‡∏ô‡∏†‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏á

---

## ‡∏™‡∏£‡∏∏‡∏õ: ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö

1. **Document Processing**: ‡πÑ‡∏ü‡∏•‡πå Markdown ‚Üí Documents ‚Üí Nodes
2. **Embedding Creation**: Text ‚Üí Vector embeddings (1024 dim)
3. **Storage**: ‡πÄ‡∏Å‡πá‡∏ö‡∏ó‡∏±‡πâ‡∏á text ‡πÅ‡∏•‡∏∞ vectors ‡πÉ‡∏ô OpenSearch
4. **Search Pipeline**: ‡∏£‡∏ß‡∏° keyword + semantic search ‡πÅ‡∏ö‡∏ö weighted
5. **Index Creation**: ‡∏™‡∏£‡πâ‡∏≤‡∏á searchable index ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

## ‡∏Ç‡πâ‡∏≠‡∏î‡∏µ‡∏Ç‡∏≠‡∏á Hybrid Search

- **Keyword Search**: ‡∏î‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á
- **Semantic Search**: ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢
- **Combined Results**: ‡πÑ‡∏î‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡πÅ‡∏•‡∏∞‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô

## ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ

‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏£‡∏±‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏ô‡∏µ‡πâ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß ‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡πÑ‡∏î‡πâ:
- OpenSearch index ‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
- ‡πÑ‡∏ü‡∏•‡πå `.pkl` ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏´‡∏•‡∏î index ‡πÉ‡∏´‡∏°‡πà
- ‡∏£‡∏∞‡∏ö‡∏ö hybrid search ‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°

---

## üîç ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô OpenSearch Index

### ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö index ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô OpenSearch
```cmd
curl -X GET "http://34.101.178.186:9200/_cat/indices?v" | more
```

### ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Ç‡∏≠‡∏á OpenSearch cluster
```cmd
curl -X GET "http://34.101.178.186:9200/_cluster/health?pretty" | more
```

### ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á OpenSearch
```cmd
curl -X GET "http://34.101.178.186:9200/" | more
```

### ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á curl ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Windows (Command Prompt)
```cmd
curl -X GET "http://34.101.178.186:9200/yourname_doc_index/_search?pretty" -H "Content-Type: application/json" -d "{\"query\": {\"match_all\": {}}}" | more
```

### ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á curl ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Windows (PowerShell)
```powershell
curl -X GET "http://34.101.178.186:9200/yourname_doc_index/_search?pretty" -H "Content-Type: application/json" -d '{
  "query": {
    "match_all": {}
  }
}' | more
```

### ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á curl ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö macOS/Linux
```bash
curl -X GET "http://34.101.178.186:9200/yourname_doc_index/_search?pretty" -H 'Content-Type: application/json' -d'{
  "query": {
    "match_all": {}
  }
}' | more
```

### Python (‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏ö‡∏ô‡∏ó‡∏∏‡∏Å OS)
```python
import requests
import json

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö OpenSearch index
endpoint = "http://34.101.178.186:9200"
index_name = "amornpan_doc_index"  # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠ index ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì

response = requests.get(f"{endpoint}/{index_name}/_search?pretty", 
                       json={"query": {"match_all": {}}})

if response.status_code == 200:
    result = response.json()
    print(f"Total documents: {result['hits']['total']['value']}")
    print(json.dumps(result, indent=2, ensure_ascii=False))
else:
    print(f"Error: {response.status_code} - {response.text}")
```

**‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏:** ‡∏≠‡∏¢‡πà‡∏≤‡∏•‡∏∑‡∏°‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô `yourname_doc_index` ‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠ index ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏ä‡πâ‡∏à‡∏£‡∏¥‡∏á